5 + 5
#Assign the variable x to 45
x <- 45
x =
x
x
softballs -> 3
softballs <-3
basketballs <-7
softballs + basketballs
softbals <-58
softballs<-8
sports <- softballs + basketballs
sports
softballs
class (softballs)
#loading libraries
library(tidyverse)
library(rio)
library(janitor)
#loading datasets
arcos <- read_csv("~/Documents/Github/natalie_weger_jour472/lab_07/data/arcos.csv")
View(arcos)
county_population <- read_csv("~/Documents/Github/natalie_weger_jour472/lab_07/data/county_population_2014.csv")
View(county_population)
#loading libraries
library(tidyverse)
library(rio)
library(janitor)
#loading datasets
arcos <- read_csv("~/Documents/Github/natalie_weger_jour472/lab_07/data/arcos.csv")
View(arcos)
county_population <- read_csv("~/Documents/Github/natalie_weger_jour472/lab_07/data/county_population_2014.csv")
View(county_population)
#finding the counties with most total opiod pills per person
arcos_total_pills <- arcos %>%
group_by(buyer_county) %>%
summarise(pills_county_grouping = sum(total_pills, na.rm = TRUE))
#loading libraries
library(tidyverse)
library(rio)
library(janitor)
#loading datasets
arcos <- read_csv("~/Documents/Github/natalie_weger_jour472/lab_07/data/arcos.csv")
View(arcos)
county_population <- read_csv("~/Documents/Github/natalie_weger_jour472/lab_07/data/county_population_2014.csv")
View(county_population)
#finding the counties with most total opiod pills per person
arcos_total_pills <- arcos %>%
group_by(buyer_county) %>%
summarise(pills_county_grouping = sum(total_pills, na.rm = TRUE))
#loading libraries
library(tidyverse)
library(rio)
library(janitor)
#loading datasets
arcos <- read_csv("~/Documents/Github/natalie_weger_jour472/lab_07/data/arcos.csv")
View(arcos)
county_population <- read_csv("~/Documents/Github/natalie_weger_jour472/lab_07/data/county_population_2014.csv")
View(county_population)
#finding the counties with most total opiod pills per person
arcos_total_pills <- arcos %>%
group_by(buyer_county) %>%
summarise(pills_county_grouping = sum(total_pills, na.rm = TRUE))
#loading libraries
library(tidyverse)
library(rio)
library(janitor)
#loading datasets
arcos <- read_csv("~/Documents/Github/natalie_weger_jour472/lab_07/data/arcos.csv")
county_population <- read_csv("~/Documents/Github/natalie_weger_jour472/lab_07/data/county_population_2014.csv")
#finding the counties with most total opiod pills per person
arcos_total_pills <- arcos %>%
group_by(buyer_county) %>%
summarise(pills_county_grouping = sum(total_pills, na.rm = TRUE))
#loading libraries
library(tidyverse)
library(rio)
library(janitor)
#loading datasets
arcos <- read_csv("~/Documents/Github/natalie_weger_jour472/lab_07/data/arcos.csv")
county_population <- read_csv("~/Documents/Github/natalie_weger_jour472/lab_07/data/county_population_2014.csv")
#finding the counties with most total opiod pills per person
arcos_total_pills <- arcos %>%
group_by(buyer_county) %>%
summarise(pills_county_grouping = sum(total_pills, na.rm = TRUE))
view (arcos_total_pills)
#loading libraries
library(tidyverse)
library(rio)
library(janitor)
#loading datasets
arcos <- read_csv("~/Documents/Github/natalie_weger_jour472/lab_07/data/arcos.csv")
county_population <- read_csv("~/Documents/Github/natalie_weger_jour472/lab_07/data/county_population_2014.csv")
#finding the counties with most total opiod pills per person
arcos_county <- arcos %>%
group_by(countyfips, buyer_county, buyer_state)%>%
summarise(
total_pills = sum(total_pills)
)%>%
inner_join(county_population, by=c("countyflips"="geoid")) %>%
mutate(pills_per_person = total_pills/total_population) %>%
arrange(desc(pills_per_person))
#loading libraries
library(tidyverse)
library(rio)
library(janitor)
#loading datasets
arcos <- read_csv("~/Documents/Github/natalie_weger_jour472/lab_07/data/arcos.csv")
county_population <- read_csv("~/Documents/Github/natalie_weger_jour472/lab_07/data/county_population_2014.csv")
#finding the counties with most total opiod pills per person
arcos_county <- arcos %>%
group_by(countyfips,buyer_county,buyer_state)%>%
summarise(
total_pills = sum(total_pills)
)%>%
inner_join(county_population, by=c("countyflips"="geoid")) %>%
mutate(pills_per_person = total_pills/total_population) %>%
arrange(desc(pills_per_person))
#loading libraries
library(tidyverse)
library(rio)
library(janitor)
#loading datasets
arcos <- read_csv("~/Documents/Github/natalie_weger_jour472/lab_07/data/arcos.csv")
county_population <- read_csv("~/Documents/Github/natalie_weger_jour472/lab_07/data/county_population_2014.csv")
#finding the counties with most total opiod pills per person
arcos_county <- arcos %>%
group_by(countyfips,buyer_county,buyer_state)%>%
summarise(
total_pills = sum(total_pills)
)%>%
inner_join(county_population, by=c("countyflips"="geoid")) %>%
mutate(pills_per_person = total_pills/total_population) %>%
arrange(desc(pills_per_person))
#loading libraries
library(tidyverse)
library(rio)
library(janitor)
#loading datasets
arcos <- read_csv("~/Documents/Github/natalie_weger_jour472/lab_07/data/arcos.csv")
county_population <- read_csv("~/Documents/Github/natalie_weger_jour472/lab_07/data/county_population_2014.csv")
#finding the counties with most total opiod pills per person
arcos_county <- arcos %>%
group_by(countyfips,buyer_county,buyer_state)%>%
summarise(
total_pills = sum(total_pills)
)%>%
inner_join(county_population, by=c("countyfips"="geoid")) %>%
mutate(pills_per_person = total_pills/total_population) %>%
arrange(desc(pills_per_person))
#loading libraries
library(tidyverse)
library(rio)
library(janitor)
#loading datasets
arcos <- read_csv("~/Documents/Github/natalie_weger_jour472/lab_07/data/arcos.csv")
county_population <- read_csv("~/Documents/Github/natalie_weger_jour472/lab_07/data/county_population_2014.csv")
#finding the counties with most total opiod pills per person
arcos_county <- arcos %>%
group_by(countyfips,buyer_county,buyer_state)%>%
summarise(
total_pills = sum(total_pills)
)%>%
inner_join(county_population, by=c("countyfips"="geoid")) %>%
mutate(pills_per_person = total_pills/total_population_2014) %>%
arrange(desc(pills_per_person))
arcos_county
#loading librarires
library(tidyverse)
library(rio)
library(janitor)
#rsw
#rsw - i can't load the data with file paths like these - it's directing me to your hard drive. the data wasn't on your github either
#downloading the data
baltimore_white <- read.csv("~/Downloads/Percent_of_Students_that_are_White_(non-Hispanic).csv")
#loading librarires
library(tidyverse)
library(rio)
library(janitor)
#rsw
#rsw - i can't load the data with file paths like these - it's directing me to your hard drive. the data wasn't on your github either
#downloading the data
baltimore_white <- read.csv("assignment1/Percent_of_Students_that_are_White_(non-Hispanic).csv ")
#loading librarires
library(tidyverse)
library(rio)
library(janitor)
#rsw
#rsw - i can't load the data with file paths like these - it's directing me to your hard drive. the data wasn't on your github either
#downloading the data
baltimore_white <- read.csv("~/Downloads/Percent_of_Students_that_are_White_(non-Hispanic).csv")
#loading librarires
library(tidyverse)
library(rio)
library(janitor)
#rsw
#rsw - i can't load the data with file paths like these - it's directing me to your hard drive. the data wasn't on your github either
#downloading the data
baltimore_white <- read.csv("Percent_of_Students_that_are_White_(non-Hispanic).csv")
setwd("~/Documents/Github/natalie_weger_jour472/assignment1")
#loading librarires
library(tidyverse)
library(rio)
library(janitor)
#rsw
#rsw - i can't load the data with file paths like these - it's directing me to your hard drive. the data wasn't on your github either
#downloading the data
baltimore_white <- read.csv("Percent_of_Students_that_are_White_(non-Hispanic).csv")
#loading librarires
library(tidyverse)
library(rio)
library(janitor)
#rsw
#rsw - i can't load the data with file paths like these - it's directing me to your hard drive. the data wasn't on your github either
#downloading the data
baltimore_white <- read.csv("white_students.csv")
#loading librarires
library(tidyverse)
library(rio)
library(janitor)
#rsw
#rsw - i can't load the data with file paths like these - it's directing me to your hard drive. the data wasn't on your github either
#downloading the data
baltimore_white <- read_csv("white_students.csv")
#loading librarires
library(tidyverse)
library(rio)
library(janitor)
#rsw
#rsw - i can't load the data with file paths like these - it's directing me to your hard drive. the data wasn't on your github either
#downloading the data
baltimore_white <- read.csv("Percent_of_Students_that_are_White_(non-Hispanic).csv")
#loading librarires
library(tidyverse)
library(rio)
library(janitor)
#rsw
#rsw - i can't load the data with file paths like these - it's directing me to your hard drive. the data wasn't on your github either
#downloading the data
baltimore_white <- read_csv("white_students.csv")
#summarizing the data to find differences in baltimore neighborhoods
summary(baltimore_white$wstud21)
#finding the top 10 baltimore communites with highest white student population
baltimore_white %>%
select(CSA2020, wstud21) %>%
slice_max(wstud21, n = 10) %>%
arrange(desc(wstud21))
#finding the 10 baltimore communities with the lowest white student population
baltimore_white %>%
select(CSA2020, wstud21) %>%
slice_min(wstud21, n = 10) %>%
arrange(wstud21)
#rsw - i can't load the data with file paths like these - "~/Downloads/ - it's directing me to your hard drive. the data wasn't on your github either
#download reading test scores
reading_scores <- read.csv("test_scores.csv")
#finding the top 5 baltimore communites with highest reading scores
reading_scores %>%
select(Community.Statistical.Area..CSA., X2014) %>%
slice_max(X2014, n = 5) %>%
arrange(desc(X2014))
#finding the top 5 baltimore communites with lowest reading scores
reading_scores %>%
select(Community.Statistical.Area..CSA., X2014) %>%
slice_min(X2014, n = 5) %>%
arrange(X2014)
#finding the top 5 baltimore communites with highest white student population in 2014
baltimore_white %>%
select(CSA2020, wstud14) %>%
slice_max(wstud14, n = 5) %>%
arrange(desc(wstud14))
#finding the 5 baltimore communities with the lowest white student population in 2014
baltimore_white %>%
select(CSA2020, wstud14) %>%
slice_min(wstud14, n = 5) %>%
arrange(wstud14)
#creating top 5 communities with highest reading score table
top_5_communities <- reading_scores %>%
select(Community.Statistical.Area..CSA., X2014) %>%
slice_max(X2014, n = 5) %>%
arrange(desc(X2014))
#creating a chart of my above table with the top 5 baltimore communites with the highest reading scores
top_5_communities %>%
ggplot() +
coord_flip() +
geom_col(aes(x = reorder(Community.Statistical.Area..CSA., X2014), y = X2014)) +
labs(
title = "Percent of 8th grade students passing MSA reading in 2014",
x = "Communities",
y = "Percent of Students",
caption = "Source: Baltimore Neighborhood Indicator Alliance"
)
#create a column of the percentage change of the white population from 2010-2020
baltimore_white_percent <- baltimore_white %>%
select(CSA2020, wstud11, wstud21) %>%
mutate(diff_pct_wstud = (wstud21-wstud11)/wstud11) %>%
arrange(desc(diff_pct_wstud))
view(baltimore_white)
#find the top 25 communities with the biggest white population increase
baltimore_white_percent %>%
select (CSA2020, diff_pct_wstud) %>%
slice_max (diff_pct_wstud, n = 25)
view(baltimore_white)
#find the 25 communities with the biggest white population decrease
baltimore_white_percent %>%
select (CSA2020, diff_pct_wstud) %>%
slice_min (diff_pct_wstud, n = 25)
view(baltimore_white)
#rsw - i can't load the data with file paths like these - "~/Downloads/ - it's directing me to your hard drive. the data wasn't on your github either
#download reading test scores
reading_scores <- read.csv("test_scores.csv")
#finding the top 5 baltimore communites with highest reading scores
reading_scores %>%
select(Community.Statistical.Area..CSA., X2014) %>%
slice_max(X2014, n = 5) %>%
arrange(desc(X2014))
#finding the top 5 baltimore communites with lowest reading scores
reading_scores %>%
select(Community.Statistical.Area..CSA., X2014) %>%
slice_min(X2014, n = 5) %>%
arrange(X2014)
#finding the top 5 baltimore communites with highest white student population in 2014
baltimore_white %>%
select(CSA2020, wstud14) %>%
slice_max(wstud14, n = 5) %>%
arrange(desc(wstud14))
#finding the 5 baltimore communities with the lowest white student population in 2014
baltimore_white %>%
select(CSA2020, wstud14) %>%
slice_min(wstud14, n = 5) %>%
arrange(wstud14)
#creating top 5 communities with highest reading score table
top_5_communities <- reading_scores %>%
select(Community.Statistical.Area..CSA., X2014) %>%
slice_max(X2014, n = 5) %>%
arrange(desc(X2014))
#creating a chart of my above table with the top 5 baltimore communites with the highest reading scores
top_5_communities %>%
ggplot() +
coord_flip() +
geom_col(aes(x = reorder(Community.Statistical.Area..CSA., X2014), y = X2014)) +
labs(
title = "Percent of 8th grade students passing MSA reading in 2014",
x = "Communities",
y = "Percent of Students",
caption = "Source: Baltimore Neighborhood Indicator Alliance By: Natalie Weger"
)
#rsw - i can't load the data with file paths like these - "~/Downloads/ - it's directing me to your hard drive. the data wasn't on your github either
#download reading test scores
reading_scores <- read.csv("test_scores.csv")
#finding the top 5 baltimore communites with highest reading scores
reading_scores %>%
select(Community.Statistical.Area..CSA., X2014) %>%
slice_max(X2014, n = 5) %>%
arrange(desc(X2014))
#finding the top 5 baltimore communites with lowest reading scores
reading_scores %>%
select(Community.Statistical.Area..CSA., X2014) %>%
slice_min(X2014, n = 5) %>%
arrange(X2014)
#finding the top 5 baltimore communites with highest white student population in 2014
baltimore_white %>%
select(CSA2020, wstud14) %>%
slice_max(wstud14, n = 5) %>%
arrange(desc(wstud14))
#finding the 5 baltimore communities with the lowest white student population in 2014
baltimore_white %>%
select(CSA2020, wstud14) %>%
slice_min(wstud14, n = 5) %>%
arrange(wstud14)
#creating top 5 communities with highest reading score table
top_5_communities <- reading_scores %>%
select(Community.Statistical.Area..CSA., X2014) %>%
slice_max(X2014, n = 5) %>%
arrange(desc(X2014))
#creating a chart of my above table with the top 5 baltimore communites with the highest reading scores
top_5_communities %>%
ggplot() +
coord_flip() +
geom_col(aes(x = reorder(Community.Statistical.Area..CSA., X2014), y = X2014)) +
labs(
title = "Percent of 8th grade students passing MSA reading in 2014",
x = "Communities",
y = "Percent of Students",
caption = "Source: Baltimore Neighborhood Indicator Alliance\nby Natalie Weger"
)
#rsw - i can't load the data with file paths like these - "~/Downloads/ - it's directing me to your hard drive. the data wasn't on your github either
#download reading test scores
reading_scores <- read.csv("test_scores.csv")
#finding the top 5 baltimore communites with highest reading scores
reading_scores %>%
select(Community.Statistical.Area..CSA., X2014) %>%
slice_max(X2014, n = 5) %>%
arrange(desc(X2014))
#finding the top 5 baltimore communites with lowest reading scores
reading_scores %>%
select(Community.Statistical.Area..CSA., X2014) %>%
slice_min(X2014, n = 5) %>%
arrange(X2014)
#finding the top 5 baltimore communites with highest white student population in 2014
baltimore_white %>%
select(CSA2020, wstud14) %>%
slice_max(wstud14, n = 5) %>%
arrange(desc(wstud14))
#finding the 5 baltimore communities with the lowest white student population in 2014
baltimore_white %>%
select(CSA2020, wstud14) %>%
slice_min(wstud14, n = 5) %>%
arrange(wstud14)
#creating top 5 communities with highest reading score table
top_5_communities <- reading_scores %>%
select(Community.Statistical.Area..CSA., X2014) %>%
slice_max(X2014, n = 5) %>%
arrange(desc(X2014))
#creating a chart of my above table with the top 5 baltimore communites with the highest reading scores
top_5_communities %>%
ggplot() +
coord_flip() +
geom_col(aes(x = reorder(Community.Statistical.Area..CSA., X2014), y = X2014)) +
labs(
title = "Percent of 8th grade students passing MSA reading in 2014",
x = "Communities",
y = "Percent of Students",
caption = "Source: Baltimore Neighborhood Indicator Alliance\nBy Natalie Weger\n03/12/2024"
)
